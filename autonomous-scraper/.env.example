# Autonomous Web Scraping System - Environment Configuration
# Copy this file to .env and update the values as needed

# ==================== DATABASE CONFIGURATION ====================
# MongoDB connection URL
MONGO_URL=mongodb://mongo:27017

# Database and collection names
DATABASE_NAME=scraperDB
COLLECTION_NAME=jobs

# ==================== BACKEND API CONFIGURATION ====================
# API server settings
API_HOST=0.0.0.0
API_PORT=8000
API_WORKERS=1

# CORS settings (comma-separated origins)
CORS_ORIGINS=http://localhost:3000,http://127.0.0.1:3000

# Logging level (DEBUG, INFO, WARNING, ERROR)
LOG_LEVEL=INFO

# Rate limiting
RATE_LIMIT_REQUESTS=100
RATE_LIMIT_WINDOW=60

# ==================== WORKER CONFIGURATION ====================
# Worker identification
WORKER_ID=worker-1

# Job processing settings
POLL_INTERVAL=5
MAX_CONCURRENT_JOBS=3

# Scraping settings
DEFAULT_TIMEOUT=30
MAX_PAGE_SIZE=10485760
USER_AGENT=Autonomous-Scraper-Bot/1.0 (+https://github.com/autonomous-scraper)

# Browser settings
HEADLESS=true
BROWSER_TYPE=chromium

# Rate limiting for requests
MIN_REQUEST_DELAY=1.0
MAX_REQUEST_DELAY=5.0

# File storage paths
SCREENSHOTS_DIR=/app/temp/screenshots
LOGS_DIR=/app/logs

# ==================== FRONTEND CONFIGURATION ====================
# Backend API URL for frontend
REACT_APP_API_URL=http://localhost:8000

# ==================== DEVELOPMENT SETTINGS ====================
# Enable development mode features
DEVELOPMENT_MODE=false

# Enable debug logging
DEBUG=false

# Enable performance monitoring
ENABLE_METRICS=true

# ==================== SECURITY SETTINGS ====================
# JWT secret key (generate a secure random string)
JWT_SECRET_KEY=your-super-secret-jwt-key-change-this-in-production

# API key for worker authentication (optional)
WORKER_API_KEY=your-worker-api-key

# Enable HTTPS redirect
FORCE_HTTPS=false

# ==================== OPTIONAL INTEGRATIONS ====================
# Redis URL for caching and rate limiting (optional)
REDIS_URL=redis://localhost:6379

# Elasticsearch URL for search functionality (optional)
ELASTICSEARCH_URL=http://localhost:9200

# Webhook URL for job notifications (optional)
WEBHOOK_URL=

# Email settings for notifications (optional)
SMTP_HOST=
SMTP_PORT=587
SMTP_USERNAME=
SMTP_PASSWORD=
SMTP_FROM_EMAIL=

# ==================== MONITORING AND ALERTING ====================
# Prometheus metrics endpoint
METRICS_ENABLED=false
METRICS_PORT=9090

# Health check settings
HEALTH_CHECK_INTERVAL=30
HEALTH_CHECK_TIMEOUT=10

# Alert thresholds
ALERT_FAILED_JOBS_THRESHOLD=10
ALERT_MEMORY_THRESHOLD=80
ALERT_CPU_THRESHOLD=80

# ==================== BACKUP AND MAINTENANCE ====================
# Database backup settings
BACKUP_ENABLED=false
BACKUP_SCHEDULE=0 2 * * *
BACKUP_RETENTION_DAYS=30

# Log rotation settings
LOG_ROTATION_ENABLED=true
LOG_MAX_SIZE=100MB
LOG_BACKUP_COUNT=5

# ==================== PRODUCTION OVERRIDES ====================
# Override settings for production deployment
# Uncomment and modify as needed

# MONGO_URL=mongodb://username:password@mongo-cluster:27017/scraperDB?authSource=admin
# API_WORKERS=4
# MAX_CONCURRENT_JOBS=10
# HEADLESS=true
# LOG_LEVEL=WARNING
# FORCE_HTTPS=true
# ENABLE_METRICS=true
